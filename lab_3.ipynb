{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply read in the data\n",
    "column_labels = ['patient_id', 'diagnosis', 'mean radius', 'mean texture', 'mean perimeter', 'mean area','mean smoothness', 'mean compactness', 'mean concavity','mean concave points', 'mean symmetry', 'mean fractal dimension','radius error', 'texture error', 'perimeter error', 'area error','smoothness error', 'compactness error', 'concavity error','concave points error', 'symmetry error','fractal dimension error', 'worst radius', 'worst texture','worst perimeter', 'worst area', 'worst smoothness','worst compactness', 'worst concavity', 'worst concave points','worst symmetry', 'worst fractal dimension']\n",
    "\n",
    "# Note: Might need to change this path to the data\n",
    "df = pd.read_csv(\"../data/wdbc.data\", names=column_labels, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show it just to be safe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does exactly what it looks like\n",
    "df[\"diagnosis\"].replace(\"B\", \"Benign\", inplace=True)\n",
    "df[\"diagnosis\"].replace(\"M\", \"Malignant\", inplace=True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates two df's one with just the features, and one with all the labes (correct values) that we associate it with\n",
    "\n",
    "feature_df = df.iloc[:, 2:]\n",
    "label_df = df.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scales all the columns togeather,  so they're within the same range\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = StandardScaler().fit_transform(feature_df)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check\n",
    "np.mean(x), np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# n components = 2 because we want to plot it in 2d. \n",
    "pca = PCA(n_components=2) # Just creates an instance of a PCA\n",
    "pca_data = pca.fit_transform(x) # Adds the data\n",
    "pca_df = pd.DataFrame(data=pca_data, columns=[\"PC1\", \"PC2\"]) # creates a df with that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This show how much of the variance is explained by each principal component (sp?)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "\n",
    "targets = [\"Benign\", \"Malignant\"]\n",
    "colors = [\"b\", \"r\"]\n",
    "\n",
    "for target, color in zip(targets, colors):\n",
    "        indToKeep = label_df == target\n",
    "        plt.scatter(pca_df.loc[indToKeep, \"PC1\"],\n",
    "                   pca_df.loc[indToKeep, \"PC2\"],\n",
    "                   c=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA().fit(x) # Just fit because we don't need to actually map the data to the PCA, which is what transform does\n",
    "evr = pca2.explained_variance_ratio_\n",
    "print(\"\\n\".join(\"{:2d}\\t{:0.4f}\".format(*k) for k in enumerate(evr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca2.explained_variance_ratio_))\n",
    "plt.xlabel(\"Num components\")\n",
    "plt.ylabel(\"%\")\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
